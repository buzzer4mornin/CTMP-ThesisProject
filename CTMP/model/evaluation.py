import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
import pickle

# ======================================================================================================================
# =============================================== Read Data ============================================================

# with open("../saved-outputs/phi.pkl", "rb") as f:
#    phi = pickle.load(f)

with open("../saved-outputs/rating_GroupForUser.pkl", "rb") as f:
    rating_GroupForUser = pickle.load(f)

with open("../saved-outputs/rating_GroupForMovie.pkl", "rb") as f:
    rating_GroupForMovie = pickle.load(f)

mu = np.load("../saved-outputs/mu.npy")
shp = np.load("../saved-outputs/shp.npy")
rte = np.load("../saved-outputs/rte.npy")

# ======================================================================================================================
# ============================================ Generate Test Set =======================================================
generator = np.random.RandomState(42)
permutation = generator.permutation(len(rating_GroupForUser))
test_size = 500
c = 0
test_user_ids = []
for i in permutation:
    if len(rating_GroupForUser[i]) > 0:
        test_user_ids.append(i)
        c += 1
    if c == test_size:
        break


# ======================================================================================================================
# ============================ Compute Average Recalls and Precisions for Top-M ========================================

# size of noncold items - 20,323 (out of 25,900)
noncold_items = []
cold_items = []
for movie_id in range(len(rating_GroupForMovie)):
    if len(rating_GroupForMovie[movie_id]) != 0:
        noncold_items.append(movie_id)
    else:
        cold_items.append(movie_id)


def per_user(user_id, TOP_M, in_matrix):
    ratings = np.dot((shp[user_id] / rte[user_id]), mu.T)
    if in_matrix:
        predicted_top_M = []
        sorted_ratings = np.argsort(-ratings)
        t = 0
        for i in range(TOP_M):
            if sorted_ratings[i] not in cold_items:
                predicted_top_M.append(sorted_ratings[i])
                t += 1
            if t == TOP_M:
                break

        # TODO: second way
        # predicted_top_M = np.setdiff1d(np.argsort(-ratings), cold_items)[:TOP_M]
        # z = np.setdiff1d(np.argsort(-ratings), cold_items)
        # predicted_top_M = z[:TOP_M]

    else:
        predicted_top_M = np.argsort(-ratings)[:TOP_M]
    actual = rating_GroupForUser[user_id]
    top_m_correct = np.sum(np.in1d(predicted_top_M, actual) * 1)
    '''print("User_id - ", user_id, "\n")
    print("Actuals - ", actual, "\n")

    print("both-matrix", predicted_top_M_, "\n")
    print("in-matrix", predicted_top_M, "\n")

    #print(top_m_correct, top_m_correct_)

    print(np.in1d(predicted_top_M_, actual) * 1)

    print(list(cold_items).index(4579))'''

    recall = top_m_correct / len(np.setdiff1d(rating_GroupForUser[user_id], cold_items))
    precision = top_m_correct / TOP_M
    return recall, precision


def average_recalls_precisions(top_start, top_end):
    r, p = [], []
    for top in range(top_start, top_end):
        print("iteration:", top)
        recall_sum, precision_sum = 0, 0
        for usr in test_user_ids:
            i, j = per_user(usr, top, in_matrix=True)
            recall_sum += i
            precision_sum += j
        avg_recall = recall_sum / test_size
        avg_precision = precision_sum / test_size
        r.append(avg_recall)
        p.append(avg_precision)
    return r, p


avg_r, avg_p = average_recalls_precisions(1, 100)
print(avg_r)
print(avg_p)

"""PLOT RECALL GRAPH"""
fig, ax = plt.subplots()
ax.plot(range(1, 100), avg_r, label="CTMP")
ax.set_xlabel('Top-M')
ax.set_ylabel('Recall')
ax.set_title(f"Test size of {test_size} users")
ax.legend()
plt.grid()
plt.show()

"""PLOT PRECISION GRAPH"""
fig, ax = plt.subplots()
ax.plot(range(1, 100), avg_p, label="CTMP")
ax.set_xlabel('Top-M')
ax.set_ylabel('Precision')
ax.set_title(f"Test size of {test_size} users")
ax.legend()
plt.grid()
plt.show()

# ======================================================================================================================
# =============================================== Saved Results ========================================================


# --- Set size = 20,000 ---
# print(avg_r)
# [0.01784680656920733, 0.03169878628104182, 0.04437435032167525, 0.05608892081920784, 0.06738491200224303, 0.07808928640998648, 0.08837328139020317, 0.09837232544164595, 0.10750051633546114, 0.1164594012468283, 0.12505174690767568, 0.13318530204337115, 0.14124223452285173, 0.14902208744947187, 0.15655218267285442, 0.16380460177762082, 0.17094008496222632, 0.1778000593106248, 0.18436159935762234, 0.1907713017489363, 0.19702096216591, 0.20328507960863615, 0.20933279336684013, 0.21506877751856301, 0.2206469160370103, 0.2264446806235904, 0.23169661482973755, 0.23680925507956613, 0.24201330188120218, 0.246938763758624, 0.25165691229643594, 0.25661698142791506, 0.261199215537102, 0.2657959626850624, 0.27040510293567727, 0.27487919972009167, 0.2792083471064198, 0.2833388003074418, 0.2876297820834329, 0.2920504527457827, 0.2960373988191255, 0.29996295348567337, 0.30386891259378235, 0.30790410909307403, 0.31156831617537334, 0.3154218784291747, 0.31909288509872463, 0.322711328393623, 0.3261898204776719, 0.3297174026865774, 0.3331926153586127, 0.33673509520083306, 0.3400585061042942, 0.343354209174548, 0.3466807194349613, 0.3499224787724623, 0.3531271987834479, 0.35626630122244207, 0.3595345339153375, 0.36250081055968997, 0.3656512854023823, 0.36860966755288094, 0.3716312759956289, 0.3745460238421111, 0.3775659507577103, 0.38034602627544367, 0.3831364892818601, 0.38580433016823185, 0.3886658227854483, 0.3914535648862287, 0.3942520014548438, 0.3969686512230458, 0.3996586921759634, 0.4021093560683113, 0.4047261094941198, 0.4071302916246092, 0.4095356226558145, 0.4119921217424117, 0.41449082285173333, 0.4168793366177508, 0.41926580718122985, 0.4216641320023996, 0.42406937796744726, 0.42652524732863056, 0.42889447888417387, 0.43119474923274176, 0.4335100477537775, 0.4357409311753944, 0.43794057596747227, 0.44020358748883265, 0.4423532099619404, 0.44453648690299435, 0.4467181193782184, 0.4487940260884985, 0.45096861017191975, 0.453034812735194, 0.4550760127025117, 0.4571357155923325, 0.4590637031991701]
# print(avg_p)
# [0.5779, 0.5356, 0.508333333333332, 0.4902, 0.4772499999999996, 0.4657250000000007, 0.45587857142857174, 0.4478375, 0.43968333333334747, 0.43202500000000393, 0.4246772727272571, 0.4176333333333329, 0.4114076923076781, 0.4056964285714225, 0.40013666666663783, 0.394559375, 0.38974117647054957, 0.3848611111111179, 0.380165789473693, 0.3757075000000028, 0.3715880952381136, 0.3675659090909136, 0.36355217391305567, 0.359654166666668, 0.35594999999995397, 0.3525903846153824, 0.34902407407407743, 0.34536607142857256, 0.3421931034482544, 0.3389283333333376, 0.3356806451612458, 0.3327671875, 0.329642424242373, 0.3267294117647071, 0.32396999999999004, 0.3211861111111084, 0.31853108108107453, 0.31577763157894795, 0.3133076923076902, 0.3109899999999982, 0.30852073170726707, 0.3060464285714349, 0.30371860465118605, 0.30152045454545684, 0.2992066666666621, 0.297057608695655, 0.29494255319149526, 0.2928343749999995, 0.2907316326530876, 0.2887329999999981, 0.2867803921568165, 0.28495288461538615, 0.28300377358490075, 0.28117870370370157, 0.279397272727229, 0.27763571428571554, 0.27584122807017014, 0.2740844827586135, 0.2724042372881286, 0.27070083333333594, 0.26909999999999934, 0.26749112903225486, 0.265888888888915, 0.26431953125, 0.26283769230766624, 0.26134393939393413, 0.25989925373134837, 0.2584323529411798, 0.25698478260871044, 0.25561928571428405, 0.25426408450705046, 0.2528708333333336, 0.2515561643835695, 0.25014189189189145, 0.24888866666662698, 0.24754671052631394, 0.2462162337662352, 0.2449442307692275, 0.24371139240504985, 0.24244937499999905, 0.24124012345678897, 0.24002195121950132, 0.23884457831326855, 0.23770535714285862, 0.23655529411760953, 0.23540872093024276, 0.2342747126436776, 0.23317386363636552, 0.2320612359550697, 0.23098944444444297, 0.22988626373626575, 0.22883749999999908, 0.2278370967741586, 0.22677234042553424, 0.22576842105262418, 0.22475208333333313, 0.22378247422679812, 0.22278673469388968, 0.22178131313130192]
